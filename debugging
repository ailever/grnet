/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Traceback (most recent call last):
  File "train.py", line 282, in <module>
    train(opt)
  File "train.py", line 176, in train
    model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data['gts'], torch.arange(0, len(data['gts'])), sc_flag)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 153, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_host/docker_containers/paper/grnet/misc/loss_wrapper.py", line 20, in forward
    loss = self.crit(self.model(fc_feats, att_feats, labels, att_masks), labels[:,1:], masks[:,1:]);
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_host/docker_containers/paper/grnet/models/CaptionModel.py", line 34, in forward
    return getattr(self, '_'+mode)(*args, **kwargs)
  File "/local_host/docker_containers/paper/grnet/models/AttModel.py", line 119, in _forward
    output = self.core(xt, p_fc_feats, p_att_feats, pp_att_feats, p_att_masks)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_host/docker_containers/paper/grnet/models/BertAoAModel.py", line 239, in forward
    x = self.transformer_encoder(src=x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/transformer.py", line 179, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() got an unexpected keyword argument 'src_mask'
--start_from log/log_paper_head
tensorboardX is not installed
* opt.nhead : 2
* opt.nlayer : 6
* opt.gramschmidt : None
* opt.input_json : data/cocotalk.json
* opt.input_fc_dir : data/stylized_cocotalk_fc
* opt.input_att_dir : data/stylized_cocotalk_att
* opt.input_box_dir : data/cocotalk_box
* opt.input_label_h5 : data/cocotalk_label.h5
* opt.start_from : log/log_paper_head
* opt.cached_tokens : coco-train-idxs
* opt.caption_model : aoa
* opt.rnn_size : 1024
* opt.num_layers : 2
* opt.rnn_type : lstm
* opt.input_encoding_size : 1024
* opt.att_hid_size : 512
* opt.fc_feat_size : 2048
* opt.att_feat_size : 2048
* opt.logit_layers : 1
* opt.use_bn : 0
* opt.mean_feats : 1
* opt.refine : 1
* opt.refine_aoa : 1
* opt.use_ff : 0
* opt.dropout_aoa : 0.3
* opt.ctx_drop : 1
* opt.decoder_type : BertAoA
* opt.use_multi_head : 2
* opt.num_heads : 8
* opt.multi_head_scale : 1
* opt.use_warmup : 0
* opt.acc_steps : 1
* opt.norm_att_feat : 0
* opt.use_box : 0
* opt.norm_box_feat : 0
* opt.max_epochs : 1
* opt.batch_size : 10
* opt.grad_clip : 0.1
* opt.drop_prob_lm : 0.5
* opt.self_critical_after : -1
* opt.seq_per_img : 5
* opt.beam_size : 1
* opt.max_length : 20
* opt.length_penalty : 
* opt.block_trigrams : 0
* opt.remove_bad_endings : 0
* opt.optim : adam
* opt.learning_rate : 0.0002
* opt.learning_rate_decay_start : 0
* opt.learning_rate_decay_every : 3
* opt.learning_rate_decay_rate : 0.8
* opt.optim_alpha : 0.9
* opt.optim_beta : 0.999
* opt.optim_epsilon : 1e-08
* opt.weight_decay : 0
* opt.label_smoothing : 0.2
* opt.noamopt : False
* opt.noamopt_warmup : 2000
* opt.noamopt_factor : 1
* opt.reduce_on_plateau : False
* opt.scheduled_sampling_start : 0
* opt.scheduled_sampling_increase_every : 5
* opt.scheduled_sampling_increase_prob : 0.05
* opt.scheduled_sampling_max_prob : 0.5
* opt.val_images_use : -1
* opt.save_checkpoint_every : 6000
* opt.save_history_ckpt : 0
* opt.checkpoint_path : log/log_paper_head
* opt.language_eval : 1
* opt.losses_log_every : 25
* opt.load_best_score : 1
* opt.id : paper_head
* opt.train_only : 0
* opt.cider_reward_weight : 1
* opt.bleu_reward_weight : 0
*====================== INFO ======================*
DataLoader loading json file:  data/cocotalk.json
vocab size is  9487
DataLoader loading h5 file:  data/stylized_cocotalk_fc data/stylized_cocotalk_att data/cocotalk_box data/cocotalk_label.h5
max sequence length in data is 16
read 123287 image features
assigned 113287 images to split train
assigned 5000 images to split val
assigned 5000 images to split test
Read data: 0.4125194549560547
[debug] xt : torch.Size([50, 18, 1024])
[debug] p_att_feats : torch.Size([50, 196, 1024])
[debug] x : torch.Size([50, 214, 1024])
Save ckpt on exception ...
model saved to log/log_paper_head/model.pth
Save ckpt done.
Traceback (most recent call last):
  File "train.py", line 176, in train
    model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data['gts'], torch.arange(0, len(data['gts'])), sc_flag)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 153, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_host/docker_containers/paper/grnet/misc/loss_wrapper.py", line 20, in forward
    loss = self.crit(self.model(fc_feats, att_feats, labels, att_masks), labels[:,1:], masks[:,1:]);
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/local_host/docker_containers/paper/grnet/misc/utils.py", line 140, in forward
    true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
RuntimeError: invalid argument 4: Index tensor must have same size as output tensor apart from the specified dimension at /pytorch/aten/src/THC/generic/THCTensorScatterGather.cu:328

Terminating BlobFetcher
