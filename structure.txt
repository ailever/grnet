

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/transformer.py/_get_clones
def _get_clones(module, N):
    return ModuleList([copy.deepcopy(module) for i in range(N)])
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/transformer.py/TransformerEncoder
    def __init__(self, encoder_layer, num_layers, norm=None):
        super(TransformerEncoder, self).__init__()
        self.layers = _get_clones(encoder_layer, num_layers)
        self.num_layers = num_layers
        self.norm = norm
    def forward(self, src, mask=None, src_key_padding_mask=None):
        output = src
        for mod in self.layers:
            output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)
models/BertAoAModel.py/BertAoA_Decoder_Core
    def __init__(self, opt):
        super(BertAoA_Decoder_Core, self).__init__()
        self.encoder_layer = TransformerEncoderLayer(d_model=opt.rnn_size, nhead=opt.nhead, dim_feedforward=opt.rnn_size * 4, dropout=opt.drop_prob_lm)
        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=opt.nlayer)
    def forward(self, xt, mean_feats, att_feats, p_att_feats, att_masks=None):
        x = torch.cat([xt, p_att_feats], dim=1)
        x = self.transformer_encoder(src=x)
models/BertAoAModel.py/BertAoAModel
	self.core = BertAoA_Decoder_Core(opt)
models/AttModel/py
	output = self.core(xt, p_fc_feats, p_att_feats, pp_att_feats, p_att_masks)
train.py/train
            model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data['gts'], torch.arange(0, len(data['gts'])), sc_flag)
misc/loss_wrapper.py/LossWrapper
    def __init__(self, model, opt):
		self.crit = utils.LabelSmoothing(smoothing=opt.label_smoothing)
    def forward(self, fc_feats, att_feats, labels, masks, att_masks, gts, gt_indices,
                sc_flag):
        if not sc_flag:
            loss = self.crit(self.model(fc_feats, att_feats, labels, att_masks), labels[:,1:], masks[:,1:]);






















TL : INPUT

T     [2] : model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data['gts'], torch.arange(0, len(data['gts'])), sc_flag)
T   [1-8] : p_fc_feats, p_att_feats, pp_att_feats, p_att_masks = self._prepare_feature(fc_feats, att_feats, att_masks)
T [3-1-6] : output, state = self.get_logprobs_state(it, p_fc_feats, p_att_feats, pp_att_feats, p_att_masks, state)
0   [1-7] : att = self.attention(h_att.unsqueeze(1), att_feats, p_att_feats, attn_mask=att_masks)[0]

BL : OUTPUT
--------------------------------------------------------------------------


[1]models/BertAoAModel.py
	- [1-1] MultiHeadedDotAttention
	- [1-2] AoA_Refiner_Layer
	- [1-3] AoA_Refiner_Core
	- [1-4] AoA_Decoder_Core
	- [1-5] TransformerEncoder
	- [1-6] TransformerEncoderLayer
	- [1-7] BertAoA_Decoder_Core
	- [1-8] BertAoAModel

[2]train.py


[3] model/AttModel.py
	- [3-1] AttModel
		- [3-1-1] __init__
		- [3-1-2] init_hidden
		- [3-1-3] clip_att
		- [3-1-4] _prepare_feature
		- [3-1-5] _forward
		- [3-1-6] get_logprobs_state

