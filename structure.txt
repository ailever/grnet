
TL : INPUT

T     [2] : model_out = dp_lw_model(fc_feats, att_feats, labels, masks, att_masks, data['gts'], torch.arange(0, len(data['gts'])), sc_flag)
T   [1-8] : p_fc_feats, p_att_feats, pp_att_feats, p_att_masks = self._prepare_feature(fc_feats, att_feats, att_masks)
T [3-1-6] : output, state = self.get_logprobs_state(it, p_fc_feats, p_att_feats, pp_att_feats, p_att_masks, state)
0   [1-7] : att = self.attention(h_att.unsqueeze(1), att_feats, p_att_feats, attn_mask=att_masks)[0]

BL : OUTPUT
--------------------------------------------------------------------------
[1]models/BertAoAModel.py
	- [1-1] MultiHeadedDotAttention
	- [1-2] AoA_Refiner_Layer
	- [1-3] AoA_Refiner_Core
	- [1-4] AoA_Decoder_Core
	- [1-5] TransformerEncoder
	- [1-6] TransformerEncoderLayer
	- [1-7] BertAoA_Decoder_Core
	- [1-8] BertAoAModel

[2]train.py


[3] model/AttModel.py
	- [3-1] AttModel
		- [3-1-1] __init__
		- [3-1-2] init_hidden
		- [3-1-3] clip_att
		- [3-1-4] _prepare_feature
		- [3-1-5] _forward
		- [3-1-6] get_logprobs_state

